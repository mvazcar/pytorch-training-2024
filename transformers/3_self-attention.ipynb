{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "380478ca-79e3-49a0-8676-ee8cf2dea112",
   "metadata": {},
   "source": [
    "# BERT Step by Step: Self-Attention\n",
    "\n",
    "In the context of deep learning, attention is a mechanism that enables a model to focus on specific parts of input data while processing information. It allows the model to assign varying degrees of importance or relevance to different elements of the input, rather than treating all elements uniformly.\n",
    "\n",
    "Attention mechanisms have been widely employed in natural language processing tasks, such as machine translation, text summarization, and sentiment analysis, as well as in computer vision applications, allowing models to selectively attend to relevant regions of an image or sequence. The concept is inspired by human cognitive processes that involve selectively focusing on specific information to better comprehend and process complex data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef9a343-af66-40c2-bbb2-ae0473c41e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from transformers import AutoConfig, AutoTokenizer\n",
    "from transformers import BertForPreTraining\n",
    "\n",
    "import utils\n",
    "%config InlineBackend.figure_format = 'svg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cd3506-1e3c-4cf0-8663-e000df0a6865",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = 'bert-base-uncased'\n",
    "\n",
    "model = BertForPreTraining.from_pretrained(model_checkpoint)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "config = AutoConfig.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87b5c19-faa4-47e5-bb34-f4d607ba26fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tokenizer.encode(\"let's tokenize something as an example for this notebook?\",\n",
    "                            return_tensors=\"pt\")\n",
    "tokens = tokenizer.convert_ids_to_tokens(encoding.flatten())\n",
    "seq_embedding = model.bert.embeddings.word_embeddings(encoding)\n",
    "seq_embedding.shape   # (batch_size, seq_len, hidden_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0a2547-b1d4-4522-a52d-a8d6b34795fa",
   "metadata": {},
   "source": [
    "### Cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41381c92-e925-4557-a323-8293d9eda29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_cos = F.cosine_similarity(seq_embedding[0].unsqueeze(1), seq_embedding, dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae8a41a-72f9-41a6-8c84-21f004ad263a",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot_matrix(scores_cos.detach().numpy(), tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3200fc53-59b0-4516-ad15-fe0b718eda0d",
   "metadata": {},
   "source": [
    "### Simple Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c18a60-fcfb-4fe5-8e22-5118035c76f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch matrix multiplication\n",
    "# gives all the dot products between the embeddings in the sequence\n",
    "scores = torch.bmm(seq_embedding, seq_embedding.transpose(1, 2))\n",
    "\n",
    "weights = F.softmax(scores, dim=-1)\n",
    "\n",
    "# Weighted average\n",
    "seq_embedding_att = torch.bmm(weights, seq_embedding)\n",
    "seq_embedding_att.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbeab265-291b-4dd2-8d18-fb9dbef26e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are using [1:, 1:] to take the `[CLS]` and `[SEP]` tokens out of the plot\n",
    "utils.plot_matrix(weights.detach().numpy()[0][1:, 1:], tokens[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56da616-ddb7-4cbb-8c4c-2866fdbec247",
   "metadata": {},
   "source": [
    "### Scaled dot product attention\n",
    "\n",
    "> from Natural Language Processing with Transformers, Revised Edition\n",
    "\n",
    "The basic attention mechanism above will assign a very large score to identical words in the context, and in particular to the current word itself: the dot product of a query with itself is 1. But in practice, the meaning of a word will be better informed by complementary words in the context than by identical words—for example, the meaning of “flies” is better defined by incorporating information from “time” and “arrow” than by another mention of “flies”.\n",
    "Let’s allow the model to create a different set of vectors for the query, key, and value of a token by using three different linear projections to project our initial token vector into three different spaces.\n",
    "\n",
    "$$\n",
    "Q = W^{\\text{q}}E\n",
    "$$\n",
    "$$\n",
    "K = W^{\\text{k}}E\n",
    "$$\n",
    "$$\n",
    "V = W^{\\text{v}}E\n",
    "$$\n",
    "\n",
    "Now the first matrix multiplication $EE^{\\text{T}}$ that we did to get the similarities becomes $EQ^{\\text{T}}$:\n",
    "$$\n",
    "\\color{black} QK^{\\text{T}}\n",
    "$$\n",
    "Then that's normalized by the square root of the size of the matrix $d_k$ and a softmax function is applied to it.\n",
    "Now the attention coefficients are\n",
    "$$\n",
    "a_{ij} = \\text{softmax} \\left( \\frac{Q K^{\\text{T}}}{\\sqrt{d_k}} \\right)_{ij}\n",
    "% a = \\text{softmax} \\left( \\frac{\\mathbf{q} \\cdot \\mathbf{k}}{\\sqrt{d_k}} \\right)\n",
    "$$\n",
    "\n",
    "In the scaled dot product attention, the $a_{ij}$ are normalized with a softmax to ensure all the columns or rows sum to 1.\n",
    "\n",
    "$$\n",
    "\\text{seq}^* \\equiv \\text{E}^*_{ij} = \\sum_k^{\\mathrm{hid\\ size}} a_{ik}v_{kj}\n",
    "$$\n",
    "\n",
    "We often see the whole thing written in one step as\n",
    "$$\n",
    "\\text{E}^* = \\text{softmax} \\left( \\frac{Q K^{\\text{T}}}{\\sqrt{d_k}} \\right)V\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf23270-fcdf-4c79-8d6c-9699934a26e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "head_dim = config.hidden_size // config.num_attention_heads\n",
    "\n",
    "query = nn.Linear(config.hidden_size, 64, bias=False)(seq_embedding)  # Q = W_qE\n",
    "key   = nn.Linear(config.hidden_size, 64, bias=False)(seq_embedding)  # K = W_kE\n",
    "value = nn.Linear(config.hidden_size, 64, bias=False)(seq_embedding)  # V = W_vE\n",
    "\n",
    "dim_k = query.shape[-1]\n",
    "\n",
    "scores = torch.bmm(query, key.transpose(1, 2)) / torch.math.sqrt(dim_k)  # QK^T / sqrt(dim_k)\n",
    "\n",
    "weights = F.softmax(scores, dim=-1)  # softmax(QK^T / sqrt(dim_k))\n",
    "\n",
    "seq_embedding_att = torch.bmm(weights, value)   # softmax(QK^T / sqrt(dim_k))V\n",
    "\n",
    "\n",
    "utils.plot_matrix(weights.detach().numpy()[0], tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2988d68-3fd5-41bf-8078-5f21328e96e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(seq_embedding):\n",
    "    head_dim = config.hidden_size // config.num_attention_heads\n",
    "    query = nn.Linear(config.hidden_size, head_dim)(seq_embedding)\n",
    "    key = nn.Linear(config.hidden_size, head_dim)(seq_embedding)\n",
    "    value = nn.Linear(config.hidden_size, head_dim)(seq_embedding)\n",
    "    dim_k = query.size(-1)\n",
    "    scores = torch.bmm(query, key.transpose(1, 2)) / torch.math.sqrt(dim_k)\n",
    "    weights = F.softmax(scores, dim=-1)\n",
    "    return torch.bmm(weights, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fa261f-afc9-4e76-a7cb-070f4f886d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "att_concat = torch.cat([scaled_dot_product_attention(seq_embedding)\n",
    "                        for i in range(config.num_attention_heads)], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336c2dd5-a603-479c-b413-a851ff62dc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "att_concat.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml2024",
   "language": "python",
   "name": "ml2024"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
