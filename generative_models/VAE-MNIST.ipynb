{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational Autoencoder for MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import the usual Python suspects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to avoid surprises due to the random initialization of weights in our models, we set the random seed. See [PyTorch: Reproducibility](https://pytorch.org/docs/stable/notes/randomness.html) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "seed = 42\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we are going to build a Variational Autoencoder (VAE) to generate new images that look like the ones contained in the [MNIST]() dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start, let's define the `torch.device` we will use for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we did previously, let's download the MNIST data set. However, since we are working with a generative model and trying to learn the underlying data distribution of the training set, we don't need to worry about the validation or test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Define a [DataLoader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader) from the `trainset` data set. Use the pre-defined `batch_size` (hyperparameter), and enable shuffling of the examples. Drop the last batch (with a different batch size), to make things easier (we hard-code `batch_size` in several places, and use it for assertions).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(), # Convert PIL image to PyTorch tensor\n",
    "    transforms.Normalize(0.5, 0.5) # Normalise images: out = (in - mean) / std\n",
    "])\n",
    "\n",
    "trainset = datasets.MNIST(root=\"data/\", train=True, download=True, transform=transform)\n",
    "\n",
    "# Define the trainloader using a PyTorch DataLoader\n",
    "# TODO\n",
    "trainloader =\n",
    "\n",
    "trainiter = iter(trainloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is always a good idea to have a look at the data. Let's plot a bunch of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "images, labels = next(trainiter)\n",
    "\n",
    "fig = plt.figure(figsize=(12,12))\n",
    "for idx in range(64):\n",
    "    ax = fig.add_subplot(8, 8, idx + 1, xticks=[], yticks=[])\n",
    "    \n",
    "    img = images[idx].numpy()\n",
    "    \n",
    "    img = img * 0.5 + 0.5 \n",
    "\n",
    "    img = np.transpose(img, (1, 2, 0))\n",
    "    \n",
    "    plt.imshow(img, cmap='gray')\n",
    "    \n",
    "    name = str(labels[idx].item())\n",
    "    \n",
    "    ax.set_title(name, fontdict={\"fontsize\": 12})\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a fully connected variational autoencoder. The size of the latent space is a parameter of the model architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The encoder should be composed by linear layers with hidden dimensions `hidden_dim_1` and `hidden_dim_2`. Use `ReLU` activation functions between layers. The final layers produce what we interpret as a mean and log variance of a Gaussian distribution.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Implement the reparametrisation trick in the method `reparametrisation`.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Implement the decoder mirroring the encoder, but as a sequential model (since there is a single output). Use `tanh` as the ouptu activation function, to produce images in the range $[-1, 1]$.* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Implement the `encode` and `decode` functions. The `encode` function defines the forward pass of the encoder, and needs to take care of linearising the input (from 2D images to 1D vectors). The `decode` function defines the forward pass of the decoder, and needs to take care of reshaping the linear output into an image.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Use the `encode()`, `decode()` and `reparametrisation()` functions to define the `forward()` function.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, z_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.z_size = z_size\n",
    "        \n",
    "        hidden_dim_1 = 256\n",
    "        hidden_dim_2 = 128\n",
    "        \n",
    "        # Define the encoder layers (using hidden_dim_1 and hidden_dim_2)\n",
    "        # TODO\n",
    "        self.enc_1 =\n",
    "        self.enc_2 =\n",
    "        self.enc_mean =\n",
    "        self.enc_logvar =\n",
    "        \n",
    "        # Define the decoder\n",
    "        # TODO\n",
    "        self.decoder = nn.Sequential(\n",
    "\n",
    "        )\n",
    "        \n",
    "    def encode(self, x):\n",
    "        # Respahe the image into a linear vector\n",
    "        # TODO\n",
    "        x =\n",
    "        \n",
    "        # Apply encoder layers\n",
    "        # TODO\n",
    "        x =\n",
    "        x =\n",
    "        mean =\n",
    "        logvar = \n",
    "        \n",
    "        return mean, logvar\n",
    "    \n",
    "    def decode(self, z):\n",
    "        # Apply decoder layers\n",
    "        x_out =\n",
    "        \n",
    "        # Reshape output vector into an image (with one channel)\n",
    "        x_out =\n",
    "        \n",
    "        return x_out\n",
    "    \n",
    "    def reparametrisation(self, mean, logvar):\n",
    "        # Transform the logarithm of the variance into the standard deviation\n",
    "        # TODO\n",
    "        std =\n",
    "        \n",
    "        # Sample from the normal distribution\n",
    "        # Hing: use randn_like\n",
    "        # TODO\n",
    "        e =\n",
    "        \n",
    "        # Reparametrisation\n",
    "        # TODO\n",
    "        z = mean + std * e\n",
    "        \n",
    "        return z\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Encode x\n",
    "        # TODO\n",
    "        mean, logvar =\n",
    "        \n",
    "        # Reparametrisation trick\n",
    "        # TODO\n",
    "        z =\n",
    "        \n",
    "        # Decode z\n",
    "        # TODO\n",
    "        x_out =\n",
    "        \n",
    "        return x_out, mean, logvar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's instantiate a VAE with a latent space dimension of 10 and check that the `forward()`, `encode()` and `decode()` functions produce outputs of the correct shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = VAE(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v(torch.ones((batch_size, 1, 28, 28)))[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v.encode(torch.ones((batch_size, 1, 28, 28)))[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v.decode(torch.ones((batch_size, 10))).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Latent vector size\n",
    "z_size = 10\n",
    "\n",
    "vae = VAE(z_size).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned in the class, the variational autoencoder loss boils down to two terms: the _reconstruction loss_ (same as for an autoencoder) and the _Kullback–Leibler divergence_ loss. The latter can be computed analytically and it is given by\n",
    "$$\n",
    "    -D_\\text{KL}(q_\\phi(\\mathbf{z}|\\mathbf{x})||p_\\theta(\\mathbf{z})) = \\frac{1}{2} \\sum_j \n",
    "    \\left(1 + \\log\\left(\\sigma_j^2\\right) - \\mu_j^2 - \\sigma_j^2\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Implement the loss function:*\n",
    "  * _The reconstruction loss is the sum of squared difference between input and output_\n",
    "  * _The KL loss is defined above_\n",
    "  \n",
    "_You can implement the reconstruction loss using PyTorch's `mse_loss`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(x_out, x_in, mean, logvar, kl_weight=0.5):\n",
    "    # Reconstruction loss\n",
    "    # TODO\n",
    "    reconstruction_loss =\n",
    "    \n",
    "    # KL divergence\n",
    "    # TODO\n",
    "    kl_loss =\n",
    "    \n",
    "    return reconstruction_loss + kl_weight * kl_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimiser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the oprimizer, we use again the [Adam](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html) optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizers\n",
    "lr = 1e-3\n",
    "\n",
    "optimizer = optim.Adam(vae.parameters(), lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During training we will save some generated samples, in order to visualize how the training progressed ath the end. Therefore, we define a batch of fixed latent space vectors $z$ that we re-use each time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed data for sampling new images (for evaluation)\n",
    "sample_size = batch_size\n",
    "fixed_z = torch.randn((sample_size, z_size)).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Implement the missing bits from the training loop.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import trange, tqdm\n",
    "\n",
    "n_epochs = 30\n",
    "\n",
    "# Keep track of loss and generated, \"fake\" samples\n",
    "samples = []\n",
    "\n",
    "# Ensure the VAE is in training mode\n",
    "# TODO\n",
    "\n",
    "iters = 0\n",
    "pbar = trange(n_epochs, desc='Training', leave=True)\n",
    "for epoch in pbar:\n",
    "    \n",
    "    for images, _ in trainloader:\n",
    "     \n",
    "        x_in = images.to(device)\n",
    "    \n",
    "        # Clear gradients\n",
    "        # TODO\n",
    "\n",
    "        # Forward pass\n",
    "        # TODO\n",
    "        x_out, mean, logvar =\n",
    "        \n",
    "        # Loss\n",
    "        # TODO\n",
    "        loss =\n",
    "        \n",
    "        # Backpropagation\n",
    "        # TODO\n",
    "\n",
    "        # Update weights\n",
    "        # TODO\n",
    "        \n",
    "        if iters % 250 == 0:\n",
    "            # Generate fake images from fixed sample\n",
    "            vae.eval()\n",
    "            with torch.no_grad():\n",
    "                samples.append(vae.decode(fixed_z))\n",
    "            vae.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the generator to generate new images. We generate new latent space samples $z$ and use the generator $G(z)$ to generate new images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Create a batch (`batch_size`) of samples of the latent space (using PyTorch's `randn`) and decode them.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Ensure the model is in evaluation mode\n",
    "# TODO\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Create a batch of latent space samples\n",
    "    # Hint: ensure they are on the appropriate device\n",
    "    # TODO\n",
    "    z =\n",
    "    \n",
    "    # Decode z into images\n",
    "    # TODO\n",
    "    images =\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "for idx in range(64):\n",
    "    ax = fig.add_subplot(8, 8, idx + 1, xticks=[], yticks=[])\n",
    "\n",
    "    img = images[idx].detach().cpu().numpy()\n",
    "    \n",
    "    img = img * 0.5 + 0.5\n",
    "    \n",
    "    img = np.transpose(img, (1, 2, 0))\n",
    "    \n",
    "    ax.imshow(img, cmap='gray')\n",
    "    \n",
    "    # Get name\n",
    "    name = str(labels[idx].item())\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the generated images are pretty decent, compared to the real ones. This is especially true if we consider that the model is a feed-forward neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*As an exercise, you can implement a convolutional encoder and a convolutional decoder and see if it improves the quality of the generated images.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we stored some samples during training, we can also visualise how the generator evolves during training. On order to show more examples at the beginning of training, we use `np.logspace` to generate the indices of the time steps we want to visualize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = np.logspace(0, np.log10(len(samples) - 1), num=10, dtype=int)\n",
    "ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n = len(ss)\n",
    "\n",
    "fig = plt.figure(figsize=(12,12))\n",
    "for row, s in enumerate(ss):\n",
    "    for col in range(10):\n",
    "        ax = fig.add_subplot(n, 10, col + 10 * row + 1, xticks=[], yticks=[])\n",
    "\n",
    "        img = samples[s][col].detach().cpu().numpy()\n",
    "        \n",
    "        img = img * 0.5 + 0.5\n",
    "\n",
    "        img = np.transpose(img, (1, 2, 0))\n",
    "        \n",
    "        ax.imshow(img, cmap='gray')\n",
    "\n",
    "        # Remove axes\n",
    "        ax.xaxis.set_visible(False)\n",
    "        ax.yaxis.set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*If you have time, you can try to explore the structure of the latent space, or perform interpolations in latent space.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
