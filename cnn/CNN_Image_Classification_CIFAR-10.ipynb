{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81546d97-7f3c-4b32-b12d-b15543a33d13",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network for Image Classification (CIFAR-10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999d1b14-8ad8-4c0a-91bb-28c629ae235e",
   "metadata": {},
   "source": [
    "In this exercise we are going to implement and train a convolutional neural network (CNN) for classifying images in the [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html) data set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38e9389",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910d9a08",
   "metadata": {},
   "source": [
    "Let's start by importing PyTorch and a few important modules (`nn` and `optim`, as well as a shortand for [`nn.functional`](https://pytorch.org/docs/stable/nn.functional.html)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f92233",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581423ac",
   "metadata": {},
   "source": [
    "When working with images, the [`torchvision`](https://pytorch.org/vision/stable/index.html) package is extremely useful. It contains common datasets, useful image transformations, as well as pre-trained models (which we will exploit later on in the course):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2831f0-8ded-4df4-835b-9805fbbdb510",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be49caf",
   "metadata": {},
   "source": [
    "[scikit-learn](https://scikit-learn.org/stable/) is a very popular library for machine learning, and includes many useful tools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1beb5e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc92aa9",
   "metadata": {},
   "source": [
    "Finally, let's import the usual suspects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f07ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0158df0-ed5a-45f4-9aa5-531a50665e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028b4629-f53e-4ebe-8faa-7fb2c0633e9a",
   "metadata": {},
   "source": [
    "## Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b11a5e-6a4d-40da-9d2f-ebcdcfa4c1ad",
   "metadata": {},
   "source": [
    "### [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff2aa3b-9507-43e5-936d-89e2f2afe83d",
   "metadata": {},
   "source": [
    "The [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html) data set consists of $60000$ $32 \\times 32$ colour images in 10 classes, with 6000 images per class. There are $50000$ training images and $10000$ test images in the dataset.\n",
    "\n",
    "The 10 classes, which are mutually exclusive, are the following:\n",
    "* Airplane\n",
    "* Automobile\n",
    "* Bird\n",
    "* Cat\n",
    "* Deer\n",
    "* Dog\n",
    "* Frog\n",
    "* Horse\n",
    "* Ship\n",
    "* Truck"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b05e2ff-90ca-419d-86bd-1506361bbf19",
   "metadata": {},
   "source": [
    "The [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html) data set is available in the [`torchvision`](https://pytorch.org/vision/stable/index.html) package."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21bf5dca",
   "metadata": {},
   "source": [
    "### Loading the Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fb0301-a4bc-45b1-8070-df54a9f14313",
   "metadata": {},
   "source": [
    "The data in [`torchvision`](https://pytorch.org/vision/stable/index.html) data sets consists of [PIL](https://pillow.readthedocs.io/en/stable/reference/Image.html) images with values in the interval $[0, 1]$. In order to use the images for training, they need to be converted to PyTorch tensors ([`torch.Tensor`](https://pytorch.org/docs/stable/tensors.html)). It is also good practice to normalise the images on the interval $[-1, 1]$ to reduce data skewness."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb80a89-946c-4c25-bd12-cceb7cbac1c8",
   "metadata": {},
   "source": [
    "*Define a transformation, using `torchvision.transforms`, converting PIL images to PyTorch tensors and normalising them (with mean and standard deviation of `0.5` for each channel):*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bb5da8-b7f4-4224-8c8c-253452b99d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    # TODO\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00cf932",
   "metadata": {},
   "source": [
    "Using the transformation defined above, we can define and download the training and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469ad8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = datasets.CIFAR10(\"data/\", download=True, train=True, transform=transform)\n",
    "testset = datasets.CIFAR10(\"data/\", download=True, train=False, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f54b1be",
   "metadata": {},
   "source": [
    "We do not want to look at the test set until the very end, when the model is trained and we are happy about its performance. In order to evaluate the model performance, we need to define a validation set which is taken out from the training set. A simple way of creating the validation set is to randomly sub-sample the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9911c7eb",
   "metadata": {},
   "source": [
    "[scikit-learn](https://scikit-learn.org/stable/) is an open source machine learning library that supports supervised and unsupervised learning. It also provides various tools for model fitting, data preprocessing, model selection, model evaluation, and many other utilities. Such tools are very useful to pre-process and manupulate data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35d57f1",
   "metadata": {},
   "source": [
    "*Use [scikit-learn](https://scikit-learn.org/stable/)'s `train_test_split` to define which images (i.e. which indices) of the training set are used for training and which are used for validation, using random sampling. Use 20% of training data for the validation set.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e457ec7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(trainset)\n",
    "idx_train, idx_valid = train_test_split(np.arange(n), test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f68b5ee",
   "metadata": {},
   "source": [
    "Given the indices of the training and validation sets obtained above, it is possible to define PyTorch random data samplers as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0f8b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampler = torch.utils.data.sampler.SubsetRandomSampler(idx_train)\n",
    "valid_sampler = torch.utils.data.sampler.SubsetRandomSampler(idx_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c5367d",
   "metadata": {},
   "source": [
    "A dataset and a sampler can be finally combined into a data loader, for loading/sampling trainig and validation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792cc433",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, sampler=train_sampler, drop_last=True, num_workers=2)\n",
    "validloader = torch.utils.data.DataLoader(trainset, batch_size=64, sampler=valid_sampler, drop_last=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def1589f",
   "metadata": {},
   "source": [
    "Here we chose a batch size of `64`. The batch size can have a big impact on training and therefore it is an hyperparameter of the model. We drop the last batch so that all batches have the same size, for simplicity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b73741b",
   "metadata": {},
   "source": [
    "For the test set, we just load the examples in sequence, with the same batch size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5e9850",
   "metadata": {},
   "outputs": [],
   "source": [
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False, drop_last=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76be6be",
   "metadata": {},
   "source": [
    "Finally, we can define [Python iterators](https://wiki.python.org/moin/Iterator) to iterate over `trainloader`, `validloader` and `testloader` batches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7517297f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainiter = iter(trainloader)\n",
    "validiter = iter(validloader)\n",
    "testiter = iter(testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a115d48",
   "metadata": {},
   "source": [
    "### Visualize the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ba504c",
   "metadata": {},
   "source": [
    "It is always good practice to have a proper look at the data, but especially important in machine learning and deep learning projects where data quality and pre-processing have a major impact on the outcome. Therefore, we want to have a look at the images of the [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html) to understand what they look like."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e886a373",
   "metadata": {},
   "source": [
    "First, we can define an utility dictionary to map PyTorch labels (numbers from 0 to 9) into the name of the different classes of the [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html) data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d0050b",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_name = { \n",
    "    i : name \n",
    "    for i, name in enumerate([\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]) \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba50f428",
   "metadata": {},
   "source": [
    "PyTorch stores images with in the $\\text{C} \\times \\text{H} \\times \\text{W}$ ($\\text{C}$: channels, $\\text{H}$: height, $\\text{H}$: width) convention while [Matplotlib](https://matplotlib.org/) uses the $\\text{H} \\times \\text{W} \\times \\text{C}$ convention. This means that we have to transpose our tensors from $\\text{C} \\times \\text{H} \\times \\text{W}$ to $\\text{H} \\times \\text{W} \\times \\text{C}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc16c3fd",
   "metadata": {},
   "source": [
    "*Load one batch of images, with the corresponding label, and visualize them using [Matplotlib](https://matplotlib.org/)'s [`imshow`](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.imshow.html) function. Since images are stored as PyTorch tensors, you need to do the following*:\n",
    "* _Transform PyTorch tensors into NumPy arrays_\n",
    "* _Un-normalize the data (i.e. apply the inverse of the transformation we applied when loading)_\n",
    "* _Transpose the image from from $\\text{C} \\times \\text{H} \\times \\text{W}$ (PyTorch) to $\\text{H} \\times \\text{W} \\times \\text{C}$ (Matplotlib)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df02d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(trainiter)\n",
    "\n",
    "fig = plt.figure(figsize=(12,12))\n",
    "for idx in range(64):\n",
    "    ax = fig.add_subplot(8, 8, idx + 1, xticks=[], yticks=[])\n",
    "    \n",
    "    # Transform the current image images[idx] into a NumPy array\n",
    "    # TODO\n",
    "    img =\n",
    "    \n",
    "    # Un-normalize the image\n",
    "    # TODO\n",
    "    img = \n",
    "\n",
    "    # Transpose image from C x H x W to H x W x C\n",
    "    # Use np.transpose\n",
    "    # TODO\n",
    "    img =\n",
    "    \n",
    "    plt.imshow(img)\n",
    "    \n",
    "    name = label_to_name[labels[idx].item()]\n",
    "    \n",
    "    ax.set_title(name, fontdict={\"fontsize\": 12})\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a262afc0",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc186b1a",
   "metadata": {},
   "source": [
    "Convolutional neural networks (CNNs) have been extremely succesfull in image classification tasks. Here we want to define such architecture by subclassing PyTorch's [`nn.Module`](https://pytorch.org/docs/stable/generated/torch.nn.Module.html). A simple CNN architecture consists of a feature-detection part composed of 2D convolutional layers and pooling layers and a second classification part composed of fully connected layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92fc8da9",
   "metadata": {},
   "source": [
    "*Define a simple convolutional neural network with the following characteristics:*\n",
    "* _Three convolutional layers with `16`, `32`, and `64` channels (use $3 \\times 3$ kernels)_\n",
    "* _Maximum pooling (with $2 \\times 2$ kernel)_\n",
    "* _Two fully connected layers (with an hidden dimesnion between the two layers of `512`_\n",
    "\n",
    "*For simplicity, we consider that the hard-coded batch size of `64` defined above does not change.*\n",
    "\n",
    "*You will have to:*\n",
    "  * _Choose the number of input channels (considering we are dealing with RGB images)_\n",
    "  * _Choose appropriate values for the padding so that convolutions don't change the spatial dimensions of the image_\n",
    "  * _Determine the input size of the first linear layer_\n",
    "  * _Determine the output size of the last linear layer_\n",
    "  * _Drefine the `forward()` function_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b9794e",
   "metadata": {},
   "source": [
    "The size of the convolutional and maximum pooling kernels, as well as the number of channels and fully connected layers are all hyperparameters of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fa3b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # TODO\n",
    "        self.conv1 =\n",
    "\n",
    "        # TODO\n",
    "        self.conv2 =\n",
    "\n",
    "        # TODO\n",
    "        self.conv3 =\n",
    "\n",
    "        # TODO\n",
    "        self.pool =\n",
    "\n",
    "        # TODO\n",
    "        self.fc1 =\n",
    "        self.fc2 =\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        assert x.shape == (64, 3, 32, 32)\n",
    "\n",
    "        # Apply first convolution and activation\n",
    "        # TODO\n",
    "        x =\n",
    "\n",
    "        assert x.shape == (64, 16, 32, 32)\n",
    "\n",
    "        # Apply pooling\n",
    "        # TODO\n",
    "        x =\n",
    "\n",
    "        assert x.shape == (64, 16, 16, 16)\n",
    "\n",
    "        # Apply second convolution and activation\n",
    "        # TODO\n",
    "        x =\n",
    "\n",
    "        assert x.shape == (64, 32, 16, 16)\n",
    "\n",
    "        # Apply pooling\n",
    "        # TODO\n",
    "        x =\n",
    "\n",
    "        assert x.shape == (64, 32, 8, 8)\n",
    "\n",
    "        # Apply third convolution and activation\n",
    "        # TODO\n",
    "        x =\n",
    "\n",
    "        assert x.shape == (64, 64, 8, 8)\n",
    "\n",
    "        # Apply pooling\n",
    "        # TODO\n",
    "        x =\n",
    "\n",
    "        assert x.shape == (64, 64, 4, 4)\n",
    "\n",
    "        # Flatten features for fully connected layers\n",
    "        x = x.view(-1, 64 * 4 * 4)\n",
    "\n",
    "        assert x.shape == (64, 64 * 4 * 4)\n",
    "\n",
    "        # Apply first fully connected layer and activation\n",
    "        # TODO\n",
    "        x =\n",
    "\n",
    "        assert x.shape == (64, 512)\n",
    "\n",
    "        # Apply second fully connected layer and log_softmax\n",
    "        # TODO\n",
    "        x =\n",
    "        \n",
    "        assert x.shape == (64, 10)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ec6fb0",
   "metadata": {},
   "source": [
    "In the _forward_ function above, we have inserted many assetions to check that the shapes of the input and output tensors for each operation are as expected. *Make sure you understand how the dimesnions of the tensors change.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed9d634",
   "metadata": {},
   "source": [
    "We can finally create an instance of the CNN model, to be trained:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fcfbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3781978a",
   "metadata": {},
   "source": [
    "### Training and Inference on GPUs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ab75a7",
   "metadata": {},
   "source": [
    "Using a graphical processing unit (GPU) can speed up training by several orders of magnitude. In PyTorch, it is very easy to take advantage of GPUs. We can define a `torch.device`, depending on the resources that are available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f2e0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13d550e",
   "metadata": {},
   "source": [
    "Once the device is defined, we can move the model to the device:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7521d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62aff96",
   "metadata": {},
   "source": [
    "If the device is the CPU, this call does nothing. If we move the model to the GPU instead, we will have to remember to move the data to the GPU as well during training and inference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800cc07e",
   "metadata": {},
   "source": [
    "### Test Forward Pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2607c941",
   "metadata": {},
   "source": [
    "To check that the model definition works correctly, we can propagate on batch of images through the network. As mentioned above, important to move the data to the same device of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6c5319",
   "metadata": {},
   "source": [
    "To make the exercise a bit more interesting, we can show the class probabilities obtained from the forward pass of one batch of images with the un-trained model. We expect the prediction to be random, so a class probability around `0.1` for each of the 10 classes in the dataset. The following utility function can be used to show class probabilities:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0c16ce-f070-43b4-898a-52b4d86a75b9",
   "metadata": {},
   "source": [
    "*Implement the forward pass of a batch of images, and the computation of class probabilities given the model output. Remember: the model output is `log_softmax`, while class probabilities are given by `softmax`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b0710d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def showclassp(images, labels, model, misclassified=False):\n",
    "    \"\"\"\n",
    "    Plot class probabilities for a batch of images and labels.\n",
    "    \"\"\"\n",
    "    \n",
    "    from collections import namedtuple\n",
    "    Misclassified = namedtuple(\"Misclassified\", \"idx label\")\n",
    "    \n",
    "    fig = plt.figure(figsize=(14,12))\n",
    "    \n",
    "    failed = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "            # Perform a forward pass of the batch of `images`\n",
    "            # TODO\n",
    "            out =\n",
    "            \n",
    "            # Compute class probabilities\n",
    "            # TODO\n",
    "            p =\n",
    "            \n",
    "            # Move the probability tensor to the CPU and convert to numpy array\n",
    "            p = p.cpu().numpy()\n",
    "    \n",
    "    for idx in range(64):        \n",
    "        ax = fig.add_subplot(8, 8, idx + 1, xticks=range(10), yticks=[0, 1])\n",
    "\n",
    "        for i in range(10):\n",
    "            if labels[idx] == i:\n",
    "                if labels[idx] == np.argmax(p[idx]):\n",
    "                    plt.bar(i, p[idx,i], color=\"g\")\n",
    "                else:\n",
    "                    plt.bar(i, p[idx,i], color=\"r\")\n",
    "                    \n",
    "                    failed.append(Misclassified(idx, np.argmax(p[idx])))\n",
    "            else:\n",
    "                plt.bar(i, p[idx,i], color=\"k\")\n",
    "        plt.ylim([0,1.25])\n",
    "        \n",
    "        ax.set_xticklabels(label_to_name.values(), rotation=90, fontdict={\"fontsize\": 7.5})\n",
    "        \n",
    "        name = label_to_name[labels[idx].item()]\n",
    "        ax.set_title(name, fontdict={\"fontsize\": 12})\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return failed if misclassified else  None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc5e087",
   "metadata": {},
   "source": [
    "A few important notes:\n",
    "* During inference we don't need to compute gradients and therefore we can use the `torch.no_grad()` context manager\n",
    "* Since the model outputs log probabilities, the actual probabilities are obtained through exponentiation \n",
    "* The predictions (`out`) need to be moved to the CPU, in case they have been obtained on the GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6006afc2",
   "metadata": {},
   "source": [
    "*Get a batch of training images (and labels) from `trainiter`, move the images and labels to the `device`, and use the utility function `showclassp` to show the class probabilities of the batch:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b74e90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch from `trainiter`\n",
    "# TODO\n",
    "images, labels =\n",
    "\n",
    "# Move images and labels to the device\n",
    "# TODO\n",
    "images, labels =\n",
    "\n",
    "# Show class probabilities using the utility function defined above\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520cc1ad",
   "metadata": {},
   "source": [
    "As expected, the class probabilities look pretty much the same for each class (uniform distribution) and are close to\n",
    "$1/10$, since the parameters of the neural network are initialised at random. If everything seems to work as expected, we are ready to train the convolutional neural network for image classification!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab27449",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34f4c5d",
   "metadata": {},
   "source": [
    "In order to train the model we still have to define a loss function and select an optimizer. Since our model output passes through a `F.log_softmax`function, we need to use a negative log-likelihood loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e9b694",
   "metadata": {},
   "outputs": [],
   "source": [
    "nll_loss = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0766b701",
   "metadata": {},
   "source": [
    "This is equivalent to applying the `CrossEntropyLoss` to the raw output of `nn.Linear`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c06c7b",
   "metadata": {},
   "source": [
    "For the optimizer, we use the widely used [Adam optimizer](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3bcc05-3768-4daf-8d2e-1f7833339061",
   "metadata": {},
   "source": [
    "*Define an `Adam` optimizer with a learning rate of `0.003`. Remember that you have to pass the model's parameters to the optimizer.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3756cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cf28f5",
   "metadata": {},
   "source": [
    "Note that the optrimizer needs to know about the model parameters. During training, the model parameters are adjusted by the optimizer in order to reduce the loss on the training set. The learning rate `lr` is another hyperparameter of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb9b722",
   "metadata": {},
   "source": [
    "*Implement the missing bits in  training loop (identified by comments):*\n",
    "* _Move data (images and labels) from the CPU to the `device`_\n",
    "* _Reset gradients of the optimizer_\n",
    "* _Perform forward pass_\n",
    "* _Compute the loss (tip: `torch.Tensor.item()` allows to get the element of a single-element tensor)_\n",
    "* _Perform bakcpropagation_\n",
    "* _Update the weights of the model using the optimizer_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef57686",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, loss_function, epochs, device):\n",
    "    import time\n",
    "\n",
    "    # Ensure the model is running on the device\n",
    "    model.to(device)\n",
    "\n",
    "    train_losses, valid_losses, accuracies = [], [], []\n",
    "\n",
    "    pbar = trange(epochs, desc='Training', leave=True)\n",
    "    for epoch in pbar:\n",
    "        \n",
    "        epoch_loss = 0\n",
    "        \n",
    "        # Train the model for one epoch\n",
    "        for images, labels in trainloader:\n",
    "\n",
    "            # Move data to GPU\n",
    "            # TODO\n",
    "            images, labels =\n",
    "        \n",
    "            # Reset optimizer gradients to zero\n",
    "            # TODO\n",
    "            \n",
    "            # Perform forward pass\n",
    "            # TODO\n",
    "            output =\n",
    "            \n",
    "            # Compute the loss\n",
    "            # TODO\n",
    "            loss =\n",
    "            \n",
    "            # Perform backpropagation\n",
    "            # TODO\n",
    "            \n",
    "            # Update model weights\n",
    "            # TODO\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "        # Evalutate the model on the validation set\n",
    "        valid_loss = 0\n",
    "        accuracy = 0\n",
    "\n",
    "        with torch.no_grad(): \n",
    "            for images, labels in validloader:\n",
    "\n",
    "                # Move data to GPU\n",
    "                # TODO\n",
    "                images, labels =\n",
    "                    \n",
    "                # Perform forward pass\n",
    "                # TODO\n",
    "                output =\n",
    "                    \n",
    "                # Accumulate the validation loss\n",
    "                valid_loss += loss_function(output, labels).item()\n",
    "                    \n",
    "                # Compute class probabilities\n",
    "                # TODO\n",
    "                p =\n",
    "                \n",
    "                # Compute accuracy\n",
    "                top_p, top_c = p.topk(1, dim=1) # Top prediction\n",
    "                equals = (top_c == labels.view(*top_c.shape)).type(torch.FloatTensor)\n",
    "                accuracy += torch.mean(equals)\n",
    "                    \n",
    "        train_losses.append(epoch_loss/len(trainloader))\n",
    "        valid_losses.append(valid_loss/len(validloader))\n",
    "        accuracies.append(accuracy.item()/len(validloader)*100)\n",
    "        \n",
    "        pbar.set_postfix({\"Accuracy\": accuracies[-1]})\n",
    "    \n",
    "    return train_losses, valid_losses, accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b64a93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses, valid_losses, accuracies = train(model, optimizer, nll_loss, epochs=15, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2d1f59",
   "metadata": {},
   "source": [
    "Once training is finished we can plot the loss of both the training and the validation sets as a function of the epoch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b173fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(train_losses, \"o-\", label=\"Training Loss\")\n",
    "plt.plot(valid_losses, \"o-\", label=\"Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.savefig(\"loss.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e271379b",
   "metadata": {},
   "source": [
    "We see that the validation loss decreases at first but then it starts increasing. This is caused by over-fitting: the model starts to become well tuned for the training set (as shown by the decreasing training loss) but fails to generalise to the new samples contained in the validation set. There are several techniques to deal with over-fitting, which we will see later on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b469b73",
   "metadata": {},
   "source": [
    "## Evaluation of Trained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8fab33",
   "metadata": {},
   "source": [
    "### Class Probabilities and Misclassified Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318bc3a9",
   "metadata": {},
   "source": [
    "With out trained model, we can visualise the class probabilities and predicitons for one batch of the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5582924",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(testiter)\n",
    "images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "misclassified = showclassp(images, labels, model, misclassified=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf4d63f",
   "metadata": {},
   "source": [
    "We can see that the class probabilities are no longer uniform, and in several cases the model prediction is correct. We can finally predict the classes of all images in the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c84c02",
   "metadata": {},
   "source": [
    "Let's plot the misclassified examples of this batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952522c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(np.ceil(np.sqrt(len(misclassified))))\n",
    "\n",
    "fig = plt.figure(figsize=(12,12))\n",
    "\n",
    "for i, (idx, label) in enumerate(misclassified):\n",
    "    ax = fig.add_subplot(n, n, i + 1, xticks=[], yticks=[])\n",
    "    \n",
    "    img = images[idx].cpu().numpy().squeeze() * 0.5 + 0.5\n",
    "    plt.imshow(np.transpose(img, (1, 2, 0)))    \n",
    "    \n",
    "    name = label_to_name[label]\n",
    "    true_name = label_to_name[labels[idx].item()]\n",
    "    \n",
    "    ax.set_title(f\"{name} ({true_name})\", fontdict={\"fontsize\": 12})\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c84620",
   "metadata": {},
   "source": [
    "*Comment on the misclassified examples.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1770fd12",
   "metadata": {},
   "source": [
    "*Complete the missing steps needed to obtained the predicted labels and the ground truth for the whole of the test set.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24eb660a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, testloader):\n",
    "    n = len(testloader) * 64\n",
    "    \n",
    "    y_pred = np.zeros(n)\n",
    "    y_true =np.zeros(n)\n",
    "    \n",
    "    i = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad(): \n",
    "        for images, labels in testloader:\n",
    "\n",
    "            # Move data to GPU\n",
    "            # TODO\n",
    "            images, labels =\n",
    "                \n",
    "            # Perform forward pass\n",
    "            # TODO\n",
    "            output =\n",
    "                \n",
    "            # Compute class probabilities\n",
    "            # TODO\n",
    "            p =\n",
    "                \n",
    "            # Get class of top prediction\n",
    "            p, c = torch.max(p, dim=1)\n",
    "            \n",
    "            y_pred[i*64:i*64+64] = c.cpu().numpy()\n",
    "            y_true[i*64:i*64+64] = labels.cpu().numpy()\n",
    "            \n",
    "            i += 1\n",
    "            \n",
    "    assert i == len(testloader)\n",
    "    \n",
    "    return y_pred, y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b8a9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_pred, l_true = predict(model, testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09d5f67",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3784abf6",
   "metadata": {},
   "source": [
    "The confusion matrix is a great tool to assess the quality of a multi-class classifier and spot patterns in misclassified examples. To compute the confusion matrix we can predict the classes of our test set with the trained model and use `sklearn.metrics.confusion_matrix` to get the confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c7fea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = metrics.confusion_matrix(l_pred, l_true)\n",
    "\n",
    "C100 = np.zeros(C.shape)\n",
    "for idx in range(10):\n",
    "    C100[idx,:] = C[idx,:] / np.sum(C[:, idx]) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da077e6b-f1ef-4543-bf50-e6e6cad226bc",
   "metadata": {},
   "source": [
    "Let's visualize the confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0143088a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(C100)\n",
    "plt.xticks(range(10), label_to_name.values(), rotation=90)\n",
    "plt.yticks(range(10), label_to_name.values())\n",
    "plt.colorbar()\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5096420-e611-4b19-963c-43b6269bc823",
   "metadata": {},
   "source": [
    "*Comment on the results.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c61622",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95a670c",
   "metadata": {},
   "source": [
    "From the confusion matrix, we can compute the per-class accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa9a6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(10):\n",
    "    correct_predictions = C[idx, idx]\n",
    "    total_predictions = np.sum(C[:, idx])\n",
    "    a = correct_predictions / total_predictions\n",
    "    print(f\"{label_to_name[idx]:<15}{round(a * 100, 2)}%\\t({correct_predictions:>3}/{total_predictions:>4})\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87396ff-963d-456c-942e-dc914612ba12",
   "metadata": {},
   "source": [
    "*Why some classes have less than 1000 examples in the test set?*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc995c68",
   "metadata": {},
   "source": [
    "We can see that the accuracy is very good for some classes, but not so good for others. This was already reflected in confusion matrix, where cats and dogs are often confused. The missing samples are due to the use of `drop_last=True`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4592edf0",
   "metadata": {},
   "source": [
    "The total accuracy is given by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b841acbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.accuracy_score(l_pred, l_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe96677e",
   "metadata": {},
   "source": [
    "Not great, not terrible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cba30e2",
   "metadata": {},
   "source": [
    "*Comment on the overall accuracy of the model. Can we achieve a better result than this one?*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
