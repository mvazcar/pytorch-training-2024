{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d90abbe-bcf5-482c-9a6a-2b8f074e3753",
   "metadata": {},
   "source": [
    "# Understanding the Effect of Softmax Function\n",
    "\n",
    "In this notebook, we explore the effect of the softmax function on random logits. The softmax function is commonly used in neural networks for multi-class classification tasks, as it transforms raw logits into probability distributions across different classes.\n",
    "\n",
    "## Introduction\n",
    "\n",
    "The softmax function is a mathematical operation that takes a vector of arbitrary real numbers (logits) and transforms them into what can be interpreted as probabilities. These probabilities can be interpreted as the likelihood of an input belonging to each class in a classification problem.\n",
    "\n",
    "The softmax function is defined as follows for a vector $\\mathbf{x}$ with $n$ elements:\n",
    "\n",
    "$$\n",
    "\\text{softmax}(\\mathbf{x})_i = \\frac{e^{x_i}}{\\sum_{j=1}^{n} e^{x_j}}\n",
    "$$\n",
    "where $e$ is the base of the natural logarithm, $z_i$ is the $i$-th element of the input vector $\\mathbf{x}$, and the sum is taken over all $n$ elements of $\\mathbf{x}$.\n",
    "\n",
    "In this demonstration, we generate random logits and apply the softmax function to observe how it influences the distribution of probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5859433-2a19-4868-a618-f63e5bc42d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1642c6-c55e-4a11-82a5-f51ec1191534",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179a726e-26f2-4eec-a5c0-96f9db1dfe03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random logits\n",
    "logits = torch.randn((1, num_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4fe956-1505-45df-a6cd-a3b4934bb49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply softmax\n",
    "probabilities = F.softmax(logits, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd05be89-a586-4066-ba8f-d808983c8ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the original logits and probabilities\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "# Plot original logits\n",
    "axs[0].bar(range(num_classes), logits.squeeze().numpy())\n",
    "axs[0].set_title('Original Logits')\n",
    "axs[0].set_xlabel('Class')\n",
    "axs[0].set_ylabel('Logit Value')\n",
    "\n",
    "# Plot softmax probabilities\n",
    "axs[1].bar(range(num_classes), probabilities.squeeze().numpy())\n",
    "axs[1].set_title('Softmax Probabilities')\n",
    "axs[1].set_xlabel('Class')\n",
    "axs[1].set_ylabel('Probability')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml2024",
   "language": "python",
   "name": "ml2024"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
